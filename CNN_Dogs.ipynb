{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_17872\\3873863118.py:4: DeprecationWarning: 'imghdr' is deprecated and slated for removal in Python 3.13\n",
      "  import imghdr\n"
     ]
    }
   ],
   "source": [
    "# Necessary Packages\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imghdr\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Source: https://www.kaggle.com/datasets/mohamedchahed/dog-breeds\n",
    "# Folder is loaded and saved as a directory \"dog-breeds\"\n",
    "r_state = 27\n",
    "tf.random.set_seed(r_state)\n",
    "np.random.seed(r_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "extensions = ['png','jpg','jpeg']\n",
    "file_path = os.path.join(os.curdir,r'dog-breeds') \n",
    "\n",
    "assert os.path.exists(file_path) # check that the folder exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_some_img(folder): # removes corrupted / poor images (just in case)\n",
    "    for f in os.listdir(folder):\n",
    "        for i in os.listdir(os.path.join(folder,f)):\n",
    "            ip = os.path.join(folder,f,i)\n",
    "            try:\n",
    "                img = cv2.imread(ip) # try to see if image can be read by openCV\n",
    "                ext = imghdr.what(ip) # check for extension\n",
    "                if ext not in extensions: \n",
    "                    # check if img ext is valid (based on what is in the extensions list)\n",
    "                    print(ip)\n",
    "                    os.remove(ip)\n",
    "            except Exception as e:\n",
    "                print(ip)\n",
    "                os.remove(ip)\n",
    "\n",
    "remove_some_img(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weights(folder,digits = 1): \n",
    "    # determines class weights based on distribution of images in folder --> fewer img = greater weight\n",
    "    count = []\n",
    "    for f in os.listdir(folder):\n",
    "        count.append(len(os.listdir(os.path.join(folder,f))))\n",
    "    max_c = max(count)\n",
    "    return [round((max_c / i),digits) for i in count]\n",
    "\n",
    "weights = get_class_weights(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 541 files belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory(file_path,batch_size=16)\n",
    "# quick way to get all the images and classes collated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beagle',\n",
       " 'bulldog',\n",
       " 'dalmatian',\n",
       " 'german-shepherd',\n",
       " 'husky',\n",
       " 'labrador-retriever',\n",
       " 'poodle',\n",
       " 'rottweiler']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.class_names \n",
    "# names of the classes (dog breeds) --> same order as that of class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_p,val_p,test_p = 0.65,0.15,0.2\n",
    "# split into 65% training, 15% validation, 20% test (0.7/0.1/0/2) also works etc\n",
    "assert round(train_p + val_p + test_p, 5) == 1 # checks that fractions == 1\n",
    "\n",
    "# data partitioning process\n",
    "train_size = int(len(data)*train_p)\n",
    "val_size = int(len(data)*val_p)\n",
    "test_size = int(len(data)*test_p)\n",
    "\n",
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size+val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data (img) normalisation\n",
    "train = train.map(lambda x,y:(x/255,y))\n",
    "val = val.map(lambda x,y:(x/255,y))\n",
    "test = test.map(lambda x,y:(x/255,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomRotation(0.2),\n",
    "    tf.keras.layers.RandomTranslation(0.1, 0.1),\n",
    "    tf.keras.layers.RandomZoom(0.2),\n",
    "    tf.keras.layers.RandomFlip('horizontal'),\n",
    "])\n",
    "\n",
    "# augmentation of training set images --> some being rotated/ translated/ skewed/ flipped\n",
    "def apply_augmentations(images, labels):\n",
    "    images = data_augmentation(images)\n",
    "    return images, labels\n",
    "\n",
    "train = train.map(apply_augmentations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predefined functions to get precision, recall and f1 scores (\n",
    "# problems with tf metrics --> thus functions below used)\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    # Convert predictions to class labels\n",
    "    y_pred = tf.argmax(y_pred, axis=1)\n",
    "    y_true = tf.cast(y_true, tf.int64)\n",
    "    y_pred = tf.cast(y_pred, tf.int64)    \n",
    "    # Compute true positives\n",
    "    true_positives = tf.reduce_sum(tf.cast(tf.equal(y_true, y_pred), \n",
    "        tf.float32))\n",
    "    \n",
    "    # Compute false positives\n",
    "    all_positives = tf.reduce_sum(tf.cast(tf.not_equal(y_pred, 0), \n",
    "        tf.float32))  # Assuming background class is labeled as 0\n",
    "    predicted_positives = tf.reduce_sum(tf.cast(tf.not_equal(y_true, 0), \n",
    "        tf.float32))  # Assuming background class is labeled as 0\n",
    "    false_positives = all_positives - true_positives\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    precision = true_positives / (true_positives + false_positives + tf.keras.backend.epsilon())\n",
    "    \n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    # Convert predictions to class labels\n",
    "    y_pred = tf.argmax(y_pred, axis=1)\n",
    "    \n",
    "    # Cast data types to align them\n",
    "    y_true = tf.cast(y_true, tf.int64)\n",
    "    y_pred = tf.cast(y_pred, tf.int64)\n",
    "    \n",
    "    # Compute true positives\n",
    "    true_positives = tf.reduce_sum(tf.cast(tf.equal(y_true, y_pred), tf.float32))\n",
    "    \n",
    "    # Compute false negatives\n",
    "    all_positives = tf.reduce_sum(tf.cast(tf.not_equal(y_pred, 0), \n",
    "        tf.float32))  # Assuming background class is labeled as 0\n",
    "    actual_positives = tf.reduce_sum(tf.cast(tf.not_equal(y_true, 0), \n",
    "        tf.float32))  # Assuming background class is labeled as 0\n",
    "    false_negatives = actual_positives - true_positives\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    recall = true_positives / (true_positives + false_negatives + tf.keras.backend.epsilon())\n",
    "    \n",
    "    return recall\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    # Compute precision and recall\n",
    "    precision_val = precision(y_true, y_pred)\n",
    "    recall_val = recall(y_true, y_pred)\n",
    "    \n",
    "    # Compute F1 score\n",
    "    f1 = 2 * (precision_val * recall_val) / (precision_val + recall_val + tf.keras.backend.epsilon())\n",
    "    f1 = tf.clip_by_value(f1, 0.0, 1.0) # clip it to the specified range\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722ms/step - accuracy: 0.1231 - f1_score: 0.1414 - loss: 2.5961\n",
      "Epoch 1: val_accuracy improved from -inf to 0.25000, saving model to .\\dog_breeds_callback.keras\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 863ms/step - accuracy: 0.1241 - f1_score: 0.1423 - loss: 2.5953 - val_accuracy: 0.2500 - val_f1_score: 0.2638 - val_loss: 2.0456\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780ms/step - accuracy: 0.1668 - f1_score: 0.2016 - loss: 2.4922\n",
      "Epoch 2: val_accuracy did not improve from 0.25000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 880ms/step - accuracy: 0.1671 - f1_score: 0.2020 - loss: 2.4955 - val_accuracy: 0.2375 - val_f1_score: 0.2559 - val_loss: 1.9878\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719ms/step - accuracy: 0.2261 - f1_score: 0.2439 - loss: 2.5061\n",
      "Epoch 3: val_accuracy did not improve from 0.25000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 822ms/step - accuracy: 0.2266 - f1_score: 0.2442 - loss: 2.5063 - val_accuracy: 0.1750 - val_f1_score: 0.1908 - val_loss: 1.9695\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740ms/step - accuracy: 0.2344 - f1_score: 0.2494 - loss: 2.3547\n",
      "Epoch 4: val_accuracy improved from 0.25000 to 0.30000, saving model to .\\dog_breeds_callback.keras\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 859ms/step - accuracy: 0.2349 - f1_score: 0.2500 - loss: 2.3550 - val_accuracy: 0.3000 - val_f1_score: 0.3456 - val_loss: 1.8118\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734ms/step - accuracy: 0.2898 - f1_score: 0.3188 - loss: 2.3118\n",
      "Epoch 5: val_accuracy did not improve from 0.30000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 835ms/step - accuracy: 0.2887 - f1_score: 0.3175 - loss: 2.3143 - val_accuracy: 0.2500 - val_f1_score: 0.2726 - val_loss: 1.8499\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724ms/step - accuracy: 0.2674 - f1_score: 0.2915 - loss: 2.2123\n",
      "Epoch 6: val_accuracy did not improve from 0.30000\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 820ms/step - accuracy: 0.2675 - f1_score: 0.2915 - loss: 2.2151 - val_accuracy: 0.2125 - val_f1_score: 0.2349 - val_loss: 1.9123\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746ms/step - accuracy: 0.2940 - f1_score: 0.3295 - loss: 2.2380\n",
      "Epoch 7: val_accuracy improved from 0.30000 to 0.33750, saving model to .\\dog_breeds_callback.keras\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 869ms/step - accuracy: 0.2948 - f1_score: 0.3302 - loss: 2.2410 - val_accuracy: 0.3375 - val_f1_score: 0.3747 - val_loss: 1.7474\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721ms/step - accuracy: 0.3466 - f1_score: 0.3816 - loss: 2.1653\n",
      "Epoch 8: val_accuracy did not improve from 0.33750\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 833ms/step - accuracy: 0.3459 - f1_score: 0.3810 - loss: 2.1680 - val_accuracy: 0.2375 - val_f1_score: 0.2574 - val_loss: 2.1337\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712ms/step - accuracy: 0.3190 - f1_score: 0.3541 - loss: 2.2423\n",
      "Epoch 9: val_accuracy did not improve from 0.33750\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 813ms/step - accuracy: 0.3190 - f1_score: 0.3544 - loss: 2.2403 - val_accuracy: 0.2625 - val_f1_score: 0.3044 - val_loss: 1.7247\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725ms/step - accuracy: 0.3530 - f1_score: 0.3904 - loss: 2.1284\n",
      "Epoch 10: val_accuracy improved from 0.33750 to 0.35000, saving model to .\\dog_breeds_callback.keras\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 851ms/step - accuracy: 0.3537 - f1_score: 0.3914 - loss: 2.1258 - val_accuracy: 0.3500 - val_f1_score: 0.4601 - val_loss: 1.6569\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719ms/step - accuracy: 0.4113 - f1_score: 0.5218 - loss: 2.0346\n",
      "Epoch 11: val_accuracy improved from 0.35000 to 0.42500, saving model to .\\dog_breeds_callback.keras\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 834ms/step - accuracy: 0.4091 - f1_score: 0.5177 - loss: 2.0383 - val_accuracy: 0.4250 - val_f1_score: 0.5239 - val_loss: 1.5099\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727ms/step - accuracy: 0.4115 - f1_score: 0.4864 - loss: 2.0137\n",
      "Epoch 12: val_accuracy did not improve from 0.42500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 829ms/step - accuracy: 0.4095 - f1_score: 0.4832 - loss: 2.0144 - val_accuracy: 0.2750 - val_f1_score: 0.3284 - val_loss: 1.7602\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731ms/step - accuracy: 0.3572 - f1_score: 0.4037 - loss: 2.0544\n",
      "Epoch 13: val_accuracy did not improve from 0.42500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 833ms/step - accuracy: 0.3570 - f1_score: 0.4032 - loss: 2.0553 - val_accuracy: 0.3625 - val_f1_score: 0.3902 - val_loss: 1.5493\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743ms/step - accuracy: 0.3421 - f1_score: 0.3723 - loss: 2.0643\n",
      "Epoch 14: val_accuracy did not improve from 0.42500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 843ms/step - accuracy: 0.3424 - f1_score: 0.3731 - loss: 2.0658 - val_accuracy: 0.3625 - val_f1_score: 0.4292 - val_loss: 1.6352\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716ms/step - accuracy: 0.3805 - f1_score: 0.4499 - loss: 1.9289\n",
      "Epoch 15: val_accuracy improved from 0.42500 to 0.46250, saving model to .\\dog_breeds_callback.keras\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 834ms/step - accuracy: 0.3805 - f1_score: 0.4494 - loss: 1.9305 - val_accuracy: 0.4625 - val_f1_score: 0.5331 - val_loss: 1.5222\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723ms/step - accuracy: 0.4377 - f1_score: 0.4900 - loss: 1.8842\n",
      "Epoch 16: val_accuracy did not improve from 0.46250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 820ms/step - accuracy: 0.4380 - f1_score: 0.4908 - loss: 1.8830 - val_accuracy: 0.4500 - val_f1_score: 0.5307 - val_loss: 1.4608\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750ms/step - accuracy: 0.4531 - f1_score: 0.5343 - loss: 1.7938\n",
      "Epoch 17: val_accuracy did not improve from 0.46250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 857ms/step - accuracy: 0.4538 - f1_score: 0.5347 - loss: 1.7911 - val_accuracy: 0.4500 - val_f1_score: 0.4999 - val_loss: 1.4727\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726ms/step - accuracy: 0.4664 - f1_score: 0.5614 - loss: 1.6408\n",
      "Epoch 18: val_accuracy did not improve from 0.46250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 833ms/step - accuracy: 0.4663 - f1_score: 0.5602 - loss: 1.6443 - val_accuracy: 0.3875 - val_f1_score: 0.4257 - val_loss: 1.6614\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716ms/step - accuracy: 0.4828 - f1_score: 0.5414 - loss: 1.6989\n",
      "Epoch 19: val_accuracy improved from 0.46250 to 0.47500, saving model to .\\dog_breeds_callback.keras\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 842ms/step - accuracy: 0.4825 - f1_score: 0.5409 - loss: 1.6998 - val_accuracy: 0.4750 - val_f1_score: 0.5593 - val_loss: 1.3540\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715ms/step - accuracy: 0.5552 - f1_score: 0.6693 - loss: 1.5641\n",
      "Epoch 20: val_accuracy improved from 0.47500 to 0.51250, saving model to .\\dog_breeds_callback.keras\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 840ms/step - accuracy: 0.5545 - f1_score: 0.6687 - loss: 1.5649 - val_accuracy: 0.5125 - val_f1_score: 0.5822 - val_loss: 1.2308\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722ms/step - accuracy: 0.5568 - f1_score: 0.6553 - loss: 1.4779\n",
      "Epoch 21: val_accuracy improved from 0.51250 to 0.58750, saving model to .\\dog_breeds_callback.keras\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 847ms/step - accuracy: 0.5570 - f1_score: 0.6552 - loss: 1.4785 - val_accuracy: 0.5875 - val_f1_score: 0.6880 - val_loss: 1.2203\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731ms/step - accuracy: 0.5291 - f1_score: 0.5972 - loss: 1.4113\n",
      "Epoch 22: val_accuracy improved from 0.58750 to 0.71250, saving model to .\\dog_breeds_callback.keras\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 845ms/step - accuracy: 0.5285 - f1_score: 0.5968 - loss: 1.4139 - val_accuracy: 0.7125 - val_f1_score: 0.8665 - val_loss: 0.7523\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736ms/step - accuracy: 0.5248 - f1_score: 0.6201 - loss: 1.4950\n",
      "Epoch 23: val_accuracy did not improve from 0.71250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 841ms/step - accuracy: 0.5252 - f1_score: 0.6195 - loss: 1.4963 - val_accuracy: 0.5250 - val_f1_score: 0.6008 - val_loss: 1.1496\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754ms/step - accuracy: 0.5880 - f1_score: 0.6705 - loss: 1.5520\n",
      "Epoch 24: val_accuracy did not improve from 0.71250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 854ms/step - accuracy: 0.5869 - f1_score: 0.6691 - loss: 1.5528 - val_accuracy: 0.6750 - val_f1_score: 0.7889 - val_loss: 0.9552\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724ms/step - accuracy: 0.6154 - f1_score: 0.7516 - loss: 1.2865\n",
      "Epoch 25: val_accuracy did not improve from 0.71250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 825ms/step - accuracy: 0.6151 - f1_score: 0.7496 - loss: 1.2871 - val_accuracy: 0.5625 - val_f1_score: 0.6202 - val_loss: 1.0514\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720ms/step - accuracy: 0.5953 - f1_score: 0.7118 - loss: 1.2528\n",
      "Epoch 26: val_accuracy did not improve from 0.71250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 819ms/step - accuracy: 0.5956 - f1_score: 0.7116 - loss: 1.2551 - val_accuracy: 0.5875 - val_f1_score: 0.6690 - val_loss: 1.3584\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718ms/step - accuracy: 0.6181 - f1_score: 0.7185 - loss: 1.2293\n",
      "Epoch 27: val_accuracy improved from 0.71250 to 0.77500, saving model to .\\dog_breeds_callback.keras\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 833ms/step - accuracy: 0.6170 - f1_score: 0.7173 - loss: 1.2308 - val_accuracy: 0.7750 - val_f1_score: 0.9253 - val_loss: 0.7207\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734ms/step - accuracy: 0.5566 - f1_score: 0.6383 - loss: 1.4396\n",
      "Epoch 28: val_accuracy did not improve from 0.77500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 835ms/step - accuracy: 0.5573 - f1_score: 0.6389 - loss: 1.4356 - val_accuracy: 0.6750 - val_f1_score: 0.7934 - val_loss: 1.0261\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725ms/step - accuracy: 0.6775 - f1_score: 0.8089 - loss: 1.1131\n",
      "Epoch 29: val_accuracy did not improve from 0.77500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 825ms/step - accuracy: 0.6769 - f1_score: 0.8075 - loss: 1.1170 - val_accuracy: 0.6250 - val_f1_score: 0.7248 - val_loss: 0.9296\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728ms/step - accuracy: 0.6432 - f1_score: 0.7564 - loss: 1.2090\n",
      "Epoch 30: val_accuracy did not improve from 0.77500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 828ms/step - accuracy: 0.6432 - f1_score: 0.7560 - loss: 1.2094 - val_accuracy: 0.6625 - val_f1_score: 0.8163 - val_loss: 0.9756\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742ms/step - accuracy: 0.6606 - f1_score: 0.7506 - loss: 1.1642\n",
      "Epoch 31: val_accuracy did not improve from 0.77500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 842ms/step - accuracy: 0.6606 - f1_score: 0.7509 - loss: 1.1648 - val_accuracy: 0.6625 - val_f1_score: 0.8029 - val_loss: 1.1832\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709ms/step - accuracy: 0.6953 - f1_score: 0.8238 - loss: 1.0766\n",
      "Epoch 32: val_accuracy did not improve from 0.77500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 813ms/step - accuracy: 0.6925 - f1_score: 0.8202 - loss: 1.0840 - val_accuracy: 0.6375 - val_f1_score: 0.7317 - val_loss: 1.0618\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737ms/step - accuracy: 0.6614 - f1_score: 0.7630 - loss: 1.2260\n",
      "Epoch 33: val_accuracy did not improve from 0.77500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 840ms/step - accuracy: 0.6616 - f1_score: 0.7632 - loss: 1.2253 - val_accuracy: 0.7125 - val_f1_score: 0.8564 - val_loss: 0.9930\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734ms/step - accuracy: 0.6727 - f1_score: 0.7688 - loss: 1.0902\n",
      "Epoch 34: val_accuracy did not improve from 0.77500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 836ms/step - accuracy: 0.6722 - f1_score: 0.7685 - loss: 1.0931 - val_accuracy: 0.7500 - val_f1_score: 0.8905 - val_loss: 0.7882\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767ms/step - accuracy: 0.6952 - f1_score: 0.8117 - loss: 0.9669\n",
      "Epoch 35: val_accuracy did not improve from 0.77500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 871ms/step - accuracy: 0.6953 - f1_score: 0.8116 - loss: 0.9692 - val_accuracy: 0.7375 - val_f1_score: 0.7859 - val_loss: 0.7188\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699ms/step - accuracy: 0.7083 - f1_score: 0.7966 - loss: 0.9592\n",
      "Epoch 36: val_accuracy did not improve from 0.77500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 803ms/step - accuracy: 0.7075 - f1_score: 0.7964 - loss: 0.9598 - val_accuracy: 0.6875 - val_f1_score: 0.8204 - val_loss: 0.8517\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722ms/step - accuracy: 0.6617 - f1_score: 0.7888 - loss: 1.2084\n",
      "Epoch 37: val_accuracy did not improve from 0.77500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 820ms/step - accuracy: 0.6629 - f1_score: 0.7899 - loss: 1.2027 - val_accuracy: 0.6750 - val_f1_score: 0.7957 - val_loss: 1.1209\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739ms/step - accuracy: 0.7604 - f1_score: 0.8848 - loss: 0.9559\n",
      "Epoch 38: val_accuracy improved from 0.77500 to 0.78750, saving model to .\\dog_breeds_callback.keras\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 862ms/step - accuracy: 0.7599 - f1_score: 0.8840 - loss: 0.9564 - val_accuracy: 0.7875 - val_f1_score: 0.8679 - val_loss: 0.8258\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725ms/step - accuracy: 0.7498 - f1_score: 0.8672 - loss: 0.8821\n",
      "Epoch 39: val_accuracy did not improve from 0.78750\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 829ms/step - accuracy: 0.7487 - f1_score: 0.8658 - loss: 0.8873 - val_accuracy: 0.6750 - val_f1_score: 0.7898 - val_loss: 0.9347\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733ms/step - accuracy: 0.6920 - f1_score: 0.7988 - loss: 1.0256\n",
      "Epoch 40: val_accuracy did not improve from 0.78750\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 828ms/step - accuracy: 0.6916 - f1_score: 0.7989 - loss: 1.0270 - val_accuracy: 0.7750 - val_f1_score: 0.9294 - val_loss: 0.9799\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724ms/step - accuracy: 0.7534 - f1_score: 0.8823 - loss: 0.8827\n",
      "Epoch 41: val_accuracy did not improve from 0.78750\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 822ms/step - accuracy: 0.7531 - f1_score: 0.8812 - loss: 0.8844 - val_accuracy: 0.7875 - val_f1_score: 0.9405 - val_loss: 0.5915\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726ms/step - accuracy: 0.6994 - f1_score: 0.8202 - loss: 0.9121\n",
      "Epoch 42: val_accuracy did not improve from 0.78750\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 823ms/step - accuracy: 0.6996 - f1_score: 0.8200 - loss: 0.9117 - val_accuracy: 0.7000 - val_f1_score: 0.8390 - val_loss: 0.7068\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707ms/step - accuracy: 0.7650 - f1_score: 0.8696 - loss: 0.8131\n",
      "Epoch 43: val_accuracy did not improve from 0.78750\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 808ms/step - accuracy: 0.7648 - f1_score: 0.8693 - loss: 0.8140 - val_accuracy: 0.7250 - val_f1_score: 0.7960 - val_loss: 0.9212\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728ms/step - accuracy: 0.7360 - f1_score: 0.8459 - loss: 0.8750\n",
      "Epoch 44: val_accuracy did not improve from 0.78750\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 823ms/step - accuracy: 0.7368 - f1_score: 0.8467 - loss: 0.8760 - val_accuracy: 0.6875 - val_f1_score: 0.8274 - val_loss: 0.8244\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753ms/step - accuracy: 0.7721 - f1_score: 0.8907 - loss: 0.7960\n",
      "Epoch 45: val_accuracy improved from 0.78750 to 0.86250, saving model to .\\dog_breeds_callback.keras\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 876ms/step - accuracy: 0.7717 - f1_score: 0.8902 - loss: 0.7965 - val_accuracy: 0.8625 - val_f1_score: 0.9448 - val_loss: 0.5143\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730ms/step - accuracy: 0.7240 - f1_score: 0.8333 - loss: 0.8713\n",
      "Epoch 46: val_accuracy did not improve from 0.86250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 828ms/step - accuracy: 0.7246 - f1_score: 0.8345 - loss: 0.8702 - val_accuracy: 0.7000 - val_f1_score: 0.8016 - val_loss: 0.9833\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744ms/step - accuracy: 0.7899 - f1_score: 0.9044 - loss: 0.8227\n",
      "Epoch 47: val_accuracy did not improve from 0.86250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 840ms/step - accuracy: 0.7886 - f1_score: 0.9031 - loss: 0.8267 - val_accuracy: 0.7375 - val_f1_score: 0.9013 - val_loss: 1.0248\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726ms/step - accuracy: 0.7911 - f1_score: 0.8935 - loss: 0.8655\n",
      "Epoch 48: val_accuracy did not improve from 0.86250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 833ms/step - accuracy: 0.7903 - f1_score: 0.8930 - loss: 0.8654 - val_accuracy: 0.7750 - val_f1_score: 0.8722 - val_loss: 0.6585\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713ms/step - accuracy: 0.8180 - f1_score: 0.9271 - loss: 0.6490\n",
      "Epoch 49: val_accuracy did not improve from 0.86250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 813ms/step - accuracy: 0.8162 - f1_score: 0.9250 - loss: 0.6543 - val_accuracy: 0.7750 - val_f1_score: 0.9457 - val_loss: 0.7686\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742ms/step - accuracy: 0.7602 - f1_score: 0.8750 - loss: 0.7846\n",
      "Epoch 50: val_accuracy did not improve from 0.86250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 842ms/step - accuracy: 0.7601 - f1_score: 0.8743 - loss: 0.7861 - val_accuracy: 0.8250 - val_f1_score: 0.9384 - val_loss: 0.9192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1ce60f74790>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neural Network Model Created\n",
    "\n",
    "model = Sequential() \n",
    "model.add(Input((256,256,3))) # input layer accepting images of 256 x 256 (3 channels -> RGB)\n",
    "# RGB preferred instead of grayscale since color infomration of dogs can be helpful in distinguishing\n",
    "# between dogs that have similar features (rounded ears/ pointed snouts) whereby colour can be helpful\n",
    "# to tell them apart\n",
    "\n",
    "# Convolution and Pooling Layers Added\n",
    "model.add(Conv2D(32,(3,3),1,activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(32,(3,3),1,activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(16,(3,3),1,activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "# Layers flattened\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dense(len(data.class_names),activation='softmax')) # Predictions made\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy',f1_score])\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(os.curdir,'dog_breeds_callback.keras'),\n",
    "    monitor = 'val_accuracy',save_best_only=True,verbose=1)\n",
    "\n",
    "if os.path.exists(os.path.join(os.curdir,'dog_breeds_model.keras')): # if model has already been saved; will not fit another\n",
    "    pass \n",
    "else:\n",
    "    model.fit(train,validation_data = val,epochs = 50, \n",
    "    class_weight={k:v for k,v in enumerate(weights)},callbacks = checkpoint_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Iterate through the dataset and collect images and labels\n",
    "for image_batch, label_batch in test:\n",
    "    for image, label in zip(image_batch, label_batch):\n",
    "        images.append(image.numpy())  # Convert to numpy array if needed\n",
    "        labels.append(label.numpy())  # Convert to numpy array if needed\n",
    "\n",
    "# Converts lists to numpy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 161ms/step\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            beagle       0.87      0.93      0.90        14\n",
      "           bulldog       0.85      0.58      0.69        19\n",
      "         dalmatian       0.79      1.00      0.88        11\n",
      "   german-shepherd       0.77      0.83      0.80        12\n",
      "             husky       0.62      0.71      0.67         7\n",
      "labrador-retriever       0.69      0.82      0.75        11\n",
      "            poodle       1.00      0.83      0.91        12\n",
      "        rottweiler       0.90      0.90      0.90        10\n",
      "\n",
      "          accuracy                           0.81        96\n",
      "         macro avg       0.81      0.83      0.81        96\n",
      "      weighted avg       0.82      0.81      0.81        96\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(os.path.join(os.curdir,'dog_breeds_model.keras')): \n",
    "    # if model has been saved, pre-saved model loaded\n",
    "    model = tf.keras.models.load_model(os.path.join(os.curdir,'dog_breeds_model.keras'))\n",
    "else:\n",
    "    model.load_weights(os.path.join(os.curdir,'dog_breeds_callback.keras')) \n",
    "    # else optimal weights used to create model\n",
    "    model.save(os.path.join(os.curdir,'dog_breeds_model.keras')) \n",
    "    # model is then saved\n",
    "\n",
    "test_y_pred =  np.argmax(model.predict(images), axis=-1) \n",
    "# predictions on test data are formed & evaluated using classification report\n",
    "print(classification_report(labels,test_y_pred,target_names=data.class_names)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - accuracy: 0.7045 - f1_score: 0.8470 - loss: 0.8844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9115530848503113, 0.7291666865348816, 0.8710581660270691]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test) # compared with tensorflow's metrics which align q well"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
