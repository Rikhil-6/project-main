{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Created 2023-01-09 @ 1900 Hrs\n",
    "#Final Product at 2023-01-12 @ 1020 Hrs\n",
    "\n",
    "###packages used###\n",
    "\n",
    "import requests  #pip install requests\n",
    "from bs4 import BeautifulSoup #pip install bs4\n",
    "import re\n",
    "import pandas as pd #pip install pandas\n",
    "import openpyxl #pip install openpyxl\n",
    "\n",
    "import xlwings as xw #pip install xlwings\n",
    "\n",
    "from selenium import webdriver #pip install selenium\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager #pip install web-driver\n",
    "from selenium.webdriver.common.by import By\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_url='https://www.sdn.sg/forindividuals/Pages/Dating-Events-Month.aspx' \n",
    "# the url used for reference >> one indicating dating events hosted in the current year\n",
    "start_sheet=requests.get(start_url) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_8108\\2317457023.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(ChromeDriverManager().install())\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(content): # function specific to the url above; used to extract certain information form the html content of the url\n",
    "    soup=BeautifulSoup(content, 'html.parser')\n",
    "    info=soup.find_all(class_=\"event_cal_height1\") # information can be found under this class in the url\n",
    "\n",
    "    df=pd.DataFrame(columns=['Date','Event','Agency','Cost','Time','Venue','Details']) # creates empty dataframe\n",
    "\n",
    "    for i in info:\n",
    "        url=re.findall('<a href=\"(\\S*)\">',str(i.contents)) # uses regex to pull out relevant info\n",
    "        details=('https://www.sdn.sg'+url[0]) # full url for further info on event (useful due to unique event id it possesses)\n",
    "        extract=[x for x in re.findall('\\S*',str(i.text)) if x!='']\n",
    "        date=(' '.join(extract[:2])) # pulls out the date (in format of mon, day)\n",
    "        name=(' '.join(extract[2:extract.index('Agency')-1])) # pulls out name of event\n",
    "        agency=(' '.join(extract[extract.index('Agency')+2:extract.index('Cost')])) # pulls out agency hosting the event\n",
    "        cost=float(' '.join(extract[extract.index('Cost')+3:extract.index('Time')])) # pulls out the cost of the event (digits only)\n",
    "        time=(' '.join(extract[extract.index('Time')+2:extract.index('Venue')])) # pulls time of the event (from what time to what time)\n",
    "        venue=(' '.join(extract[extract.index('Venue')+2:])) # pulls out location of event\n",
    "        df.loc[len(df)]=[date,name,agency,cost,time,venue,details] # stores all that info in the df\n",
    "\n",
    "        df=df.iloc[::-1] # reverses order of dataframe (so that recent entries are stored on top)\n",
    "        df.index=range(0,len(df)) # ensures that index of df is continuous\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(start_url)\n",
    "curr_page_source=driver.page_source\n",
    "og=pd.DataFrame(columns=['Date','Event','Agency','Cost','Time','Venue','Details'])\n",
    "\n",
    "soup=BeautifulSoup(driver.page_source, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parent=soup.find('div',{'class':'pageLink'}) # search for pagination\n",
    "children= parent.findChildren('a',recursive=False)\n",
    "\n",
    "upper=soup.find('div',{'class':'eventmonth'})# search for month\n",
    "\n",
    "og\n",
    "for e in upper.find_all(class_='button'):\n",
    "    id=(re.findall('id=\"(.*)\" style',str(e)))[0]\n",
    "    driver.find_element(By.ID,id).click() # finds and clicks each page button on the link (necessary as url is hyperlinked)\n",
    "    # diff \n",
    "    mon=pd.DataFrame(columns=['Date','Event','Agency','Cost','Time','Venue','Details'])\n",
    "    if get_data(driver.page_source).empty:\n",
    "        print('Done')\n",
    "        break \n",
    "    else:\n",
    "        for i,child in enumerate(children):\n",
    "            driver.find_element(By.LINK_TEXT,(str(i+1))).click()\n",
    "            curr_page_source=driver.page_source\n",
    "            if (get_data(curr_page_source).empty):\n",
    "                print('Empty')\n",
    "                break \n",
    "            else:\n",
    "                n=get_data(curr_page_source)\n",
    "                mon=pd.concat([mon,n],axis=0)\n",
    "        mon=mon.sort_values('Date',ascending=False) \n",
    "    og=pd.concat([mon,og],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "og.index=(list(range(1,len(og)+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file=r\"C:\\Users\\acer\\OneDrive\\Desktop\\Results.xlsx\" # Dependent on location and all; to create excel sheet beforehand on personal computer\n",
    "xcel=pd.read_excel(excel_file)  \n",
    "\n",
    "wb=openpyxl.load_workbook(excel_file,data_only=True)\n",
    "ws=wb['Sheet1']\n",
    "clr=openpyxl.styles.PatternFill(fill_type=None)\n",
    "\n",
    "for row in ws[\"A1\":\"H2000\"]:\n",
    "    for cell in row:\n",
    "        cell.fill = clr\n",
    "\n",
    "wb.save(filename=excel_file)\n",
    "\n",
    "rows=[]\n",
    "for i,det in enumerate(og['Details']): # compares new entries based on details (owing to unique event id present in each url)\n",
    " if det not in list(xcel['Details']): # thus; even if event is added on a previous date; will still appear\n",
    "    i+=2\n",
    "    rows.append(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxl=og\n",
    "toxl.to_excel(excel_file)\n",
    "wbx = xw.Book(excel_file)\n",
    "for e in rows:\n",
    "    wbx.sheets['Sheet1'].range(f'A{e}:H{e}').color = (255,234,0)\n",
    "wbx.save(excel_file)\n",
    "wbx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1 (tags/v3.9.1:1e5d33e, Dec  7 2020, 17:08:21) [MSC v.1927 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f5816e6188795d1cc8afa4306b69c5e3a103f064a75e820fe776234e4cf83e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
